{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import shap\n",
    "import datetime\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_work_year(x):\n",
    "    if isinstance(x, str) and x.strip():\n",
    "        if x == \"< 1 year\":\n",
    "            return 0\n",
    "        elif x == \"1 year\":\n",
    "            return 1\n",
    "        elif x == \"10+ years\":\n",
    "            return 10\n",
    "        elif x.endswith(\" years\"):\n",
    "            return int(x.split(\" \")[0])\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def convert_month(x):\n",
    "    if isinstance(x, str) and \"-\" in x:\n",
    "        parts = x.split(\"-\")\n",
    "        if len(parts) == 2:\n",
    "            if parts[0].isdigit():\n",
    "                return (\n",
    "                    2000 + int(parts[0]),\n",
    "                    {\n",
    "                        \"Jan\": 1,\n",
    "                        \"Feb\": 2,\n",
    "                        \"Mar\": 3,\n",
    "                        \"Apr\": 4,\n",
    "                        \"May\": 5,\n",
    "                        \"Jun\": 6,\n",
    "                        \"Jul\": 7,\n",
    "                        \"Aug\": 8,\n",
    "                        \"Sep\": 9,\n",
    "                        \"Oct\": 10,\n",
    "                        \"Nov\": 11,\n",
    "                        \"Dec\": 12,\n",
    "                    }[parts[1]],\n",
    "                )\n",
    "            else:\n",
    "                if parts[1] == \"00\":\n",
    "                    return (\n",
    "                        2000,\n",
    "                        {\n",
    "                            \"Jan\": 1,\n",
    "                            \"Feb\": 2,\n",
    "                            \"Mar\": 3,\n",
    "                            \"Apr\": 4,\n",
    "                            \"May\": 5,\n",
    "                            \"Jun\": 6,\n",
    "                            \"Jul\": 7,\n",
    "                            \"Aug\": 8,\n",
    "                            \"Sep\": 9,\n",
    "                            \"Oct\": 10,\n",
    "                            \"Nov\": 11,\n",
    "                            \"Dec\": 12,\n",
    "                        }[parts[0]],\n",
    "                    )\n",
    "                else:\n",
    "                    return (\n",
    "                        1900 + int(parts[1]),\n",
    "                        {\n",
    "                            \"Jan\": 1,\n",
    "                            \"Feb\": 2,\n",
    "                            \"Mar\": 3,\n",
    "                            \"Apr\": 4,\n",
    "                            \"May\": 5,\n",
    "                            \"Jun\": 6,\n",
    "                            \"Jul\": 7,\n",
    "                            \"Aug\": 8,\n",
    "                            \"Sep\": 9,\n",
    "                            \"Oct\": 10,\n",
    "                            \"Nov\": 11,\n",
    "                            \"Dec\": 12,\n",
    "                        }[parts[0]],\n",
    "                    )\n",
    "        else:\n",
    "            return None, None\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def preprocess_dataset(dataset_path):\n",
    "    train_data = pd.read_csv(dataset_path)\n",
    "    train_data = train_data.fillna(train_data.median())\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_data[\"employer_type\"] = label_encoder.fit_transform(train_data[\"employer_type\"])\n",
    "    train_data[\"industry\"] = label_encoder.fit_transform(train_data[\"industry\"])\n",
    "    train_data[\"class\"] = label_encoder.fit_transform(train_data[\"class\"])\n",
    "\n",
    "    ohe = OneHotEncoder()\n",
    "    train_employer_type_oh = ohe.fit_transform(train_data[[\"employer_type\"]]).toarray()\n",
    "    train_industry_oh = ohe.fit_transform(train_data[[\"industry\"]]).toarray()\n",
    "    train_class_oh = ohe.fit_transform(train_data[[\"class\"]]).toarray()\n",
    "\n",
    "    train_data = pd.concat(\n",
    "        [\n",
    "            train_data,\n",
    "            pd.DataFrame(\n",
    "                train_employer_type_oh,\n",
    "                columns=[\n",
    "                    f\"employer_type_{i}\" for i in range(train_employer_type_oh.shape[1])\n",
    "                ],\n",
    "            ),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    train_data = pd.concat(\n",
    "        [\n",
    "            train_data,\n",
    "            pd.DataFrame(\n",
    "                train_industry_oh,\n",
    "                columns=[f\"industry_{i}\" for i in range(train_industry_oh.shape[1])],\n",
    "            ),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    train_data = pd.concat(\n",
    "        [\n",
    "            train_data,\n",
    "            pd.DataFrame(\n",
    "                train_class_oh,\n",
    "                columns=[f\"class_{i}\" for i in range(train_class_oh.shape[1])],\n",
    "            ),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # 处理日期特征\n",
    "\n",
    "    train_data[\"issue_year\"] = pd.to_datetime(\n",
    "        train_data[\"issue_date\"], format=\"%Y/%m/%d\"\n",
    "    ).dt.year\n",
    "    train_data[\"issue_month\"] = pd.to_datetime(\n",
    "        train_data[\"issue_date\"], format=\"%Y/%m/%d\"\n",
    "    ).dt.month\n",
    "    train_data[\"issue_day\"] = pd.to_datetime(\n",
    "        train_data[\"issue_date\"], format=\"%Y/%m/%d\"\n",
    "    ).dt.day\n",
    "    train_data[\"issue_date_days\"] = (\n",
    "        datetime.datetime.now()\n",
    "        - pd.to_datetime(train_data[\"issue_date\"], format=\"%Y/%m/%d\")\n",
    "    ).dt.days\n",
    "\n",
    "    # 特征工程\n",
    "    train_data[\"total_loan_per_year\"] = (\n",
    "        train_data[\"total_loan\"] / train_data[\"year_of_loan\"]\n",
    "    )\n",
    "    train_data[\"monthly_payment_per_thousand\"] = train_data[\"monthly_payment\"] / (\n",
    "        train_data[\"total_loan\"] / 1000\n",
    "    )\n",
    "\n",
    "    train_data[\"work_year\"] = train_data[\"work_year\"].apply(convert_work_year)\n",
    "    train_data[\"work_year\"] = train_data[\"work_year\"].interpolate()\n",
    "    train_data = pd.concat(\n",
    "        [train_data, pd.DataFrame(train_data[\"work_year\"], columns=[\"work_year\"])], axis=1\n",
    "    )\n",
    "    train_data = train_data.drop(\"issue_date\", axis=1)\n",
    "\n",
    "    train_data[[\"earlies_credit_year\", \"earlies_credit_month\"]] = pd.DataFrame(\n",
    "        train_data[\"earlies_credit_mon\"].apply(convert_month).tolist(),\n",
    "        columns=[\"earlies_credit_year\", \"earlies_credit_month\"],\n",
    "    )\n",
    "    train_data = train_data.drop(\"earlies_credit_mon\", axis=1)\n",
    "\n",
    "    # 特征选择\n",
    "\n",
    "    selector = VarianceThreshold(threshold=0.0)\n",
    "    train_X = selector.fit_transform(train_data.drop(\"isDefault\", axis=1))\n",
    "    selected_features = train_data.drop(\"isDefault\", axis=1).columns[selector.get_support()]\n",
    "    train_data = train_data[[\"isDefault\"] + list(selected_features)]\n",
    "\n",
    "    # 数据标准化\n",
    "    scaler = StandardScaler()\n",
    "    train_X = scaler.fit_transform(train_data.drop(\"isDefault\", axis=1))\n",
    "    train_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(train_X, columns=train_data.drop(\"isDefault\", axis=1).columns),\n",
    "            train_data[\"isDefault\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # 处理类别不平衡\n",
    "    sm = SMOTE(random_state=42)\n",
    "    train_X, train_y = sm.fit_resample(\n",
    "        train_data.drop(\"isDefault\", axis=1), train_data[\"isDefault\"]\n",
    "    )\n",
    "    train_data = pd.concat(\n",
    "        [pd.DataFrame(train_X), pd.Series(train_y, name=\"isDefault\")], axis=1\n",
    "    )\n",
    "    \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./train_public.csv\"\n",
    "if not os.path.exists(\"./preprocessed_train_public.csv\"):\n",
    "    train_data = preprocess_dataset(dataset_path)\n",
    "    train_data.to_csv(\"./preprocessed_train_public.csv\", index=False)\n",
    "else:\n",
    "    train_data = pd.read_csv(\"./preprocessed_train_public.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
